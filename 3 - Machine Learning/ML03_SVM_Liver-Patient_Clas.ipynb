{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/ilmudatapy-logo.png\" width=\"350\" align=\"center\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Prediksi Pasien Liver dengan Support Vector Machine (SVM)</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Halo, Learners!__ Di notebook ini, kita akan mempraktekkan pemodelan <i>machine learning</i> dengan algoritma __Support Vector Machine__ atau __SVM__. Disini kita juga akan mengaplikasikan beberapa jenis visualisasi data dan teknik <i>preprocessing</i> data sebelum dilakukan pemodelan. Kita juga akan coba melakukan perbandingan apabila menggunakan <i>parameter tuning</i> __GridSearchCV__ dan __RandomizedSearchCV__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 25px\">\n",
    "    <ul>\n",
    "        <li>\n",
    "            Support Vector Machine (SVM)\n",
    "        </li>\n",
    "        <li>\n",
    "            Dataset\n",
    "        </li>\n",
    "        <li>\n",
    "            Analisis dan visualisasi data\n",
    "        </li>\n",
    "        <li>\n",
    "            Preprocessing\n",
    "            <ul>\n",
    "                <li>Menangani missing values</li>\n",
    "                <li>Menangani duplikat data</li>\n",
    "                <li>Memisahkan data fitur dan target</li>\n",
    "                <li>Encoding</li>\n",
    "                <li>Normalisasi</li>\n",
    "                <li>Train test split</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            Modeling\n",
    "            <ul>\n",
    "                <li>Klasifikasi dengan Support Vector Machine (SVM)</li>\n",
    "                <li>Evaluasi</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            Parameter Tuning\n",
    "            <ul>\n",
    "                <li>GridSearchCV</li>\n",
    "                <li>RandomizedSearchCV</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-success\" style=\"margin-top: 20px\">\n",
    "    <strong>Catatan:</strong> Untuk menjalankan kode program Python di Jupyter Notebook, klik pada <i>cell</i> yang ingin di-<i>run</i> lalu tekan <kbd>Shift</kbd> + <kbd>Enter</kbd>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"margin-top: 20px\">\n",
    "    <strong>Warning!:</strong> Jika ada kode program yang <i>error</i> atau output yang dihasilkan tidak sesuai, silahkan <b>Restart & Run All</b> kernel pada bagian menu <b>Kernel</b> di menu bar Jupyter Notebook, atau <b>Restart & Clear Output</b> kernel kemudian jalankan satu per satu <i>cell</i> secara berurutan dari atas ke bawah.\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Support Vector Machine__ atau __SVM__ adalah algoritma <i>machine learning</i> yang cukup populer untuk kasus <i>supervised learning</i>. SVM dapat digunakan untuk kasus klasifikasi maupun regresi, namun kebanyakan digunakan untuk klasifikasi. \n",
    "\n",
    "Cara kerja dari algoritma ini adalah dengan membuat <i>best line</i> atau <i>decision boundary</i> yang disebut dengan __hyperplane__ yang membagi ruang n-dimensi ke dalam kelas/kategori sehingga nantinya akan dengan mudah menentukan kelas/kategori data baru. Perhatikan ilustrasi berikut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../images/svm.png 'ilustrasi SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada gambar di atas, ada dua kelas/kategori yakni lingkaran yang berwarna merah dan lingkaran yang berwarna kuning. Algoritma SVM akan membuat _hyperplane_ untuk membagi data tersebut. Garis yang berwarna biru merupakan _hyperplane_ terbaik karena memiliki margin yang jauh dari data terdekat, sedangkan garis berwarna abu-abu adalah _hyperplane_ yang buruk karena marginnya terlalu dekat dengan data terdekat pada kategori merah maupun kuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset yang digunakan adalah dataset <a href='https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset)'>ILPD (Indian Liver Patient Dataset)</a> yang berasal dari UCI Machine Learning Repository dengan informasi detail tentang tiap kolom (terurut dari awal sampai akhir) sebagai berikut:\n",
    "\n",
    "__Attribute Information:__\n",
    "\n",
    "1. __Age:__ Age of the patient\n",
    "2. __Gender:__ Gender of the patient\n",
    "3. __TB:__ Total Bilirubin\n",
    "4. __DB:__ Direct Bilirubin\n",
    "5. __Alkphos:__ Alkaline Phosphotase\n",
    "6. __Sgpt:__ Alamine Aminotransferase\n",
    "7. __Sgot:__ Aspartate Aminotransferase\n",
    "8. __TP:__ Total Protiens\n",
    "9. __ALB:__ Albumin\n",
    "10. __A/G Ratio:__ Albumin and Globulin Ratio\n",
    "11. Selector field used to split the data into two sets (labeled by the experts)\n",
    "\n",
    "Kita akan membuat model <i>machine learning</i> untuk memprediksi kelas data baru apakah termasuk pasien liver atau bukan menggunakan algoritma Support Vector Machine (SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti biasa pertama kita <i>import</i> <i>library</i> yang akan digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Mengabaikan warning yang mungkin terjadi\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya kita <i>load</i> dataset CSV ke dalam dataframe Pandas dengan <code>read_csv()</code>. Dataset ini belum memiliki <i>header</i> atau nama kolom, karena itu kita akan mendefinisikan terlebih dahulu nama kolomnya agar lebih mudah untuk proses analisis data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan nama kolom\n",
    "column_names = ['Age','Gender','Total Bilirubin','Direct Bilirubin','Alkaline Phosphotase','SGPT','SGOT','Total Protein',\n",
    "                'Albumin','Albumin and Globulin Ratio','Class']\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../datasets/Indian-Liver-Patient-Dataset-(ILPD).csv', names = column_names)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis dan visualisasi data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biasanya yang pertama kali dicek adalah informasi singkat mengenai dataset tersebut. Nah, kita dapat menggunakan <code>info()</code> untuk mendapatkannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan info dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil <code>info()</code>, dapat kita liha bahwa pada kolom <code>Albumin and Globulin Ratio</code> jumlah datanya lebih sedikit dari kolom lainnya. Ini berarti ada <i>missing values</i> disitu.\n",
    "\n",
    "Selanjutnya mari kita cek statistik deskriptifnya dengan <code>describe()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan statistik deskriptif data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>describe()</code> menampilkan statistik dari dataset seperti jumlah data (__count__), rata-rata (__mean__), standar deviasi (__std__), nilai minimum (__min__), kuartil 1 (__25%__), median/kuartil 2 (__50%__), kuartil 3 (__75%__), dan nilai maksimum (__max__) untuk tiap kolom numerik.\n",
    "\n",
    "Lalu mari kita cek jumlah data untuk tiap kategori pada kolom target yaitu <code>Class</code> dengan <code>value_counts()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan jumlah data untuk tiap kategori pada kolom 'Class'\n",
    "\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil di atas, ada __416__ data yang termasuk dalam <i>class</i> <b>1</b> (<b>Liver Patient</b>) dan <b>167</b> di <i>class</i> <b>2</b> (<b>Non Liver Patient</b>).\n",
    "\n",
    "Sekarang mari kita visualisasikan kolom <code>Class</code> berdasarkan jenis kelaminnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi data dengan countplot \n",
    "\n",
    "sns.countplot(x='Class', hue='Gender', data=df, palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ternyata untuk masing-masing <i>class</i> jumlah pasien laki-laki lebih banyak dari pasien perempuan.\n",
    "\n",
    "Kita juga dapat membuat <i>scatter plot</i>-nya. Misalnya disini kita ingin melihat sebaran 100 data pertama berdasarkan kolom <code>Age</code> dan <code>Albumin</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi 100 data pertama dengan scatter plot untuk kolom 'Class'\n",
    "\n",
    "x = df[df['Class'] == 1][0:100].plot(kind='scatter', x='Age', y='Albumin', color='SteelBlue', label='Liver Patient');\n",
    "\n",
    "df[df['Class'] == 2][0:100].plot(kind='scatter', x='Age', y='Albumin', color='Gold', label='Non Liver Patient', ax=x);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita juga dapat menggunakan histogram untuk melihat sebaran data tiap kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan histogram dari kolom fitur numerik\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(16, 10)) \n",
    "\n",
    "# Menambahkan subplot dengan indexing\n",
    "ax0 = fig.add_subplot(ax[0,0]) \n",
    "ax1 = fig.add_subplot(ax[0,1])  \n",
    "ax2 = fig.add_subplot(ax[0,2])  \n",
    "ax3 = fig.add_subplot(ax[1,0]) \n",
    "ax4 = fig.add_subplot(ax[1,1])  \n",
    "ax5 = fig.add_subplot(ax[1,2]) \n",
    "ax6 = fig.add_subplot(ax[2,0]) \n",
    "ax7 = fig.add_subplot(ax[2,1])  \n",
    "ax8 = fig.add_subplot(ax[2,2]) \n",
    "\n",
    "df.hist(column='Age', bins=50, ax=ax0)\n",
    "df.hist(column='Total Bilirubin', bins=50, ax=ax1)\n",
    "df.hist(column='Direct Bilirubin', bins=50, ax=ax2)\n",
    "df.hist(column='Alkaline Phosphotase', bins=50, ax=ax3)\n",
    "df.hist(column='SGPT', bins=50, ax=ax4)\n",
    "df.hist(column='SGOT', bins=50, ax=ax5)\n",
    "df.hist(column='Total Protein', bins=50, ax=ax6)\n",
    "df.hist(column='Albumin', bins=50, ax=ax7)\n",
    "df.hist(column='Albumin and Globulin Ratio', bins=50, ax=ax8)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita cek dimensi data dengan atribut <code>shape</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek dimensi data\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menangani missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti yang telah kita ketahui sebelumnya bahwa ada <i>missing values</i> dalam dataset tersebut. Sekarang mari kita lihat ada berapa <i>missing values</i> pada dataset ini dengan <code>isnull().sum()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek missing values pada tiap kolom\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ternyata hanya ada __4__ <i>missing values</i> pada kolom <code>Albumin dan Globulin Ratio</code>.\n",
    "\n",
    "Selanjutnya mari kita isi nilai yang hilang tersebut dengan <code>mean()</code> atau nilai rata-rata dari kolom tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengisi missing values dengan nilai rata-rata \n",
    "\n",
    "df['Albumin and Globulin Ratio'].fillna(df['Albumin and Globulin Ratio'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cek lagi jumlah <i>missing values</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek kembali missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang sudah tidak ada <i>missing values</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menangani duplikat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan mengecek apakah ada duplikat data pada dataframe <code>df</code> dengan <code>duplicated().values.any()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek duplikat data\n",
    "\n",
    "df.duplicated().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ternyata ada duplikat data dalam dataset ini. Sekarang mari kita hapus duplikat data tersebut dengan <code>drop_duplicates()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus duplikat data\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu cek lagi dimensi data setelah menghapus duplikat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek dimensi data setelah menghapus duplikat\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensi data sekarang adalah (__570, 11__) yang berarti berkurang __13__ baris data dari yang sebelumnya 583."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memisahkan data fitur dan target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya kita akan memisahkan data fitur dan target. Data targetnya adalah kolom <code>Class</code> dan sisa kolom lainnya merupakan data fitur, sehingga untuk mendefinisikan data fitur, kita hanya perlu menghapus kolom <code>Class</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan data fitur dan target\n",
    "\n",
    "df_features = df.drop('Class', axis=1)\n",
    "df_target = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita tampilkan <code>df_features</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan data fitur\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari 10 kolom yang akan digunakan sebagai fitur, kolom <code>Gender</code> masih bertipe non-numerik. Oleh karena itu, disini kita akan melakukan <i>encoding</i> pada kolom tersebut dengan <code>.cat.codes</code> dengan mengubah tipe datanya terlebih dahulu menjadi <i>category</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah tipe data 'Gender' menjadi category\n",
    "df_features['Gender'] = df_features['Gender'].astype('category')\n",
    "\n",
    "# Encoding data\n",
    "df_features['Gender'] = df_features['Gender'].cat.codes\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperti yang kita lihat bahwa <i>range</i> angka tiap kolom berbeda jauh, sehingga kita perlu melakukan normalisasi terlebih dahulu terhadap dataframe <code>df_features</code>.\n",
    "\n",
    "Disini kita akan menggunakan <code>StandardScaler</code> untuk normalisasi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Mendefinisikan nama kolom fitur\n",
    "cols = list(df_features.columns)\n",
    "\n",
    "# Normalisasi data dengan StandardScaler\n",
    "df_features_scaled = pd.DataFrame(data = df_features)\n",
    "df_features_scaled[cols] = StandardScaler().fit_transform(df_features[cols])\n",
    "df_features_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah dataframe fitur siap digunakan, sekarang kita gabungkan lagi dengan data targetnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggabungkan kembali dataframe fitur dan target\n",
    "\n",
    "df_join = pd.concat([df_features_scaled, df_target], axis=1)\n",
    "df_join.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya kita akan memisahkan <code>df_join</code> menjadi data latih dan data uji dengan <code>train_test_split</code> dengan persentase 80% data latih dan 20% data uji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Mendefinisikan fitur dan target\n",
    "X = df_join.iloc[:,:-1] \n",
    "y = df_join['Class']\n",
    "\n",
    "# Membagi data latih dan data uji dengan train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# Menampilkan dimensi data latih dan data uji\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling \n",
    "\n",
    "### Klasifikasi dengan Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk masalah klasifikasi, kita dapat menggunakan __Support Vector Classification__ atau __SVC__ dari SVM. \n",
    "\n",
    "Tahapannya sama dengan proses klasifikasi dengan algoritma lainnya, yaitu mendefinisikan model <code>SVC()</code>, melatihnya dengan <code>fit()</code>, kemudian menguji model dengan melakukan prediksi terhadap data test dengan <code>predict()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Melatih model\n",
    "model = SVC(gamma='scale').fit(X_train, y_train)\n",
    "\n",
    "# Menguji model / memprediksi dengan X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya mari kita evaluasi hasil model tersebut dengan <code>accuracy_score()</code> untuk <i>train set</i> dan <i>test set</i>-nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Menampilkan akurasi data latih dan data uji\n",
    "print('Akurasi Train set: %.3f' % accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Akurasi Test set: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter tuning adalah sebuah proses mencari kombinasi parameter yang akan menghasilkan akurasi terbaik. Di Sklearn, ada dua <i>package</i> dari <i>library</i> __model_selection__ yang dapat digunakan untuk proses parameter tuning, yaitu __GridSearchCV__ dan __RandomizedSearchCV__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>GridSearchCV</code> adalah salah satu teknik parameter tuning yang cara kerjanya yaitu dengan mencoba semua kombinasi parameter yang didefinisikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Mendefinisikan parameter yang ingin dicoba\n",
    "param_grid = {'gamma': ['auto', 'scale'], \n",
    "             'kernel': ['linear', 'sigmoid', 'poly', 'rbf'], \n",
    "             'degree': np.arange(1,6)}\n",
    "\n",
    "# Modeling dengan SVM + Grid Search\n",
    "model = SVC()\n",
    "gscv = GridSearchCV(model, param_grid, scoring='accuracy', cv=10)\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk menampilkan hasil parameter terbaik dapat menggunakan atribut <code>.best_param_</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan hasil parameter terbaik\n",
    "\n",
    "print('Parameter terbaik hasil Grid Search: ', gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk menampilkan hasil akurasi terbaik dapat menggunakan atribut <code>.best_score_</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan akurasi data latih\n",
    "\n",
    "print('Akurasi Train set: %.3f'% gscv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita uji model dengan data uji <code>X_test</code> kemudian tampilkan skor akurasinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menguji model dengan X_test\n",
    "y_pred_gscv = gscv.predict(X_test)\n",
    "\n",
    "# Menampilkan akurasi hasil pengujian\n",
    "print('Akurasi Test set: %.3f'% accuracy_score(y_test, y_pred_gscv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>RandomizedSearchCV</code> adalah salah satu teknik parameter tuning dimana parameter yang uji diambil secara acak dari parameter yang sudah didefinisikan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Mendefinisikan parameter yang ingin dicoba\n",
    "param_grid = {'gamma': ['auto', 'scale'], \n",
    "             'kernel': ['linear', 'sigmoid', 'poly', 'rbf'], \n",
    "             'degree': np.arange(1,6)}\n",
    "\n",
    "# Modeling dengan SVM + Randomized Search\n",
    "model = SVC()\n",
    "rscv = RandomizedSearchCV(model, param_grid, scoring='accuracy', cv=10)\n",
    "rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita tampilkan parameter terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan parameter terbaik\n",
    "\n",
    "print('Parameter terbaik hasil Randomized Search: ', rscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita tampilkan skor terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan hasil akurasi data latih\n",
    "\n",
    "print('Akurasi Train set: %.3f'% rscv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kemudian kita uji dengan data test <code>X_test</code> dan <i>print</i> hasil akurasinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menguji model dengan X_test\n",
    "y_pred_rscv = rscv.predict(X_test)\n",
    "\n",
    "# Menampilkan akurasi hasil pengujian\n",
    "print('Akurasi Test set: %.3f'% accuracy_score(y_test, y_pred_rscv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil RandomizedSearchCV dapat berubah-ubah karena di-<i>generate</i> secara random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright @ <a href=\"https://ilmudatapy.com/\">ilmudatapy.com</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
